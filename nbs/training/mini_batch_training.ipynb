{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f49515c4-cfa3-4faa-b48d-142ec3738277",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "import pickle,gzip,math,os,time,shutil,torch,matplotlib as mpl,numpy as np,matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from torch import tensor,nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8223acb-49f7-47a8-a010-f0d61bbb9130",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import test_close\n",
    "\n",
    "torch.set_printoptions(precision=2, linewidth=140, sci_mode=False)\n",
    "torch.manual_seed(1)\n",
    "mpl.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "path_data = Path('../data')\n",
    "path_gz = path_data/'mnist.pkl.gz'\n",
    "with gzip.open(path_gz, 'rb') as f: ((x_train, y_train), (x_valid, y_valid), _) = pickle.load(f, encoding='latin-1')\n",
    "x_train, y_train, x_valid, y_valid = map(tensor, [x_train, y_train, x_valid, y_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61d9568e-6f13-426e-a50d-76da546528bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([50000, 784]), torch.Size([50000]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0b3ac9-b82e-43f7-bae0-5e9dd6c5af93",
   "metadata": {},
   "source": [
    "### Creating a simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7c85a0c-6d07-49a6-b972-ecbd15df475a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_data, n_features = x_train.shape\n",
    "n_hidden_activations = 50\n",
    "n_out_activation = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe15f66e-fe69-4515-9fc4-c275300b511f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = [nn.Linear(n_features,n_hidden_activations),\n",
    "                       nn.ReLU(),\n",
    "                      nn.Linear(n_hidden_activations,n_out_activation)]\n",
    "    def forward(self,X):\n",
    "        x = X.clone()\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63b2e44e-09a8-4401-9944-8371e63094d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 10])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model()\n",
    "preds = model(x_train)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68f99d9-fce0-4e99-8d2b-7bf1f827278d",
   "metadata": {},
   "source": [
    "### Training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b68b28e5-c689-4a0a-94f8-424bd4117605",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "lr = 0.5 # learning rate\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "767ee634-e7fe-4acb-8bf4-b8175eb5638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds,targets):\n",
    "    return (preds.argmax(dim=1)==targets).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df7ee47f-ae9d-404f-adae-c6fd547ad23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch= 0, current loss = 0.15, accuracy = 0.95\n",
      "current epoch= 1, current loss = 0.12, accuracy = 0.96\n",
      "current epoch= 2, current loss = 0.11, accuracy = 0.95\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0,n_train_data,batch_size):\n",
    "        s = slice(i,min(n_train_data,i+batch_size))\n",
    "        x_batch,y_batch = x_train[s],y_train[s]\n",
    "        preds = model(x_batch)\n",
    "        loss = F.cross_entropy(preds,y_batch)\n",
    "        loss.backward()\n",
    "        with torch.no_grad():\n",
    "            for layer in model.layers:\n",
    "                if hasattr(layer,\"weight\"):\n",
    "                    layer.weight -= lr*layer.weight.grad\n",
    "                    layer.bias -= lr*layer.bias.grad\n",
    "                    layer.weight.grad.zero_()\n",
    "                    layer.bias.grad.zero_()\n",
    "    acc = accuracy(preds,y_batch)\n",
    "    print(f\"current epoch= {epoch}, current loss = {loss:.2f}, accuracy = {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e9ed1b-6e90-4baa-b595-25cf4ea2e9cb",
   "metadata": {},
   "source": [
    "### Using parameters and Optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68e29474-9779-467f-9b56-8f77ce61c6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModule:\n",
    "    def __init__(self):\n",
    "        self._modules = {}\n",
    "        self.l1 = nn.Linear(n_features,n_hidden_activations)\n",
    "        self.l2 = nn.Linear(n_hidden_activations,n_out_activation)\n",
    "    \n",
    "    def __setattr__(self,attr_name,value):\n",
    "        if not attr_name.startswith(\"_\"):\n",
    "            self._modules[attr_name] = value\n",
    "        super().__setattr__(attr_name,value)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self._modules}\"\n",
    "    \n",
    "    def parameters(self):\n",
    "        for layer in self._modules.values():\n",
    "            for parameter in layer.parameters():\n",
    "                yield parameter.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92844aa5-35e0-4c05-b1b8-d49d3d27b98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "module = MyModule()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "144c2fe9-61e9-4565-8c65-15c83cd2c1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'l1': Linear(in_features=784, out_features=50, bias=True), 'l2': Linear(in_features=50, out_features=10, bias=True)}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8bc9f8fa-124b-446c-843d-3d91fb84ab99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 784])\n",
      "torch.Size([50])\n",
      "torch.Size([10, 50])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for parameter in module.parameters():\n",
    "    print(parameter.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4c7f291-9535-49f4-a1a8-1ea3b05bd96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating the optim class\n",
    "class Optimizer:\n",
    "    def __init__(self,parameters,lr=0.5):\n",
    "        self.parameters = list(parameters)\n",
    "        self.lr = lr\n",
    "    \n",
    "    def step(self):\n",
    "        with torch.no_grad():\n",
    "            for parameter in self.parameters:\n",
    "                parameter -= self.lr * parameter.grad\n",
    "    \n",
    "    def zero_grad(self):\n",
    "        for parameter in self.parameters:\n",
    "            parameter.grad.data.zero_()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c37712c0-1888-47a0-ab05-96379bac5c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential( \n",
    "    nn.Linear(n_features,n_hidden_activations),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(n_hidden_activations,n_out_activation)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bf6f20c-6b0d-4991-8ad1-01012b9b5174",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Optimizer(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d2eb0a3-2134-433a-9d48-4565c6b36d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch= 0, current loss = 0.17, accuracy = 0.93\n",
      "current epoch= 1, current loss = 0.10, accuracy = 0.96\n",
      "current epoch= 2, current loss = 0.06, accuracy = 1.00\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0,n_train_data,batch_size):\n",
    "        s = slice(i,min(n_train_data,i+batch_size))\n",
    "        xb,yb = x_train[s], y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = F.cross_entropy(preds,yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    acc = accuracy(preds,yb)\n",
    "    print(f\"current epoch= {epoch}, current loss = {loss:.2f}, accuracy = {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287b4e88-ec03-4c53-aaa0-fe6f653914bd",
   "metadata": {},
   "source": [
    "we can now use pytoch optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2c1ad622-b5fd-4ea2-8740-6e5f1a620302",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25db5d44-30a3-415c-9cc2-cbafe7ee7fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = nn.Sequential( \n",
    "        nn.Linear(n_features,n_hidden_activations),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(n_hidden_activations,n_out_activation)\n",
    "    )\n",
    "    opt = optim.SGD(model.parameters(),lr=0.5)\n",
    "    return model,opt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "56b91785-137c-44c0-84c0-03663b508643",
   "metadata": {},
   "outputs": [],
   "source": [
    "model,opt = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d4ed3a7c-acc9-41a4-9f77-c122acd29a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch= 0, current loss = 0.15, accuracy = 0.96\n",
      "current epoch= 1, current loss = 0.08, accuracy = 0.98\n",
      "current epoch= 2, current loss = 0.06, accuracy = 0.99\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for i in range(0,n_train_data,batch_size):\n",
    "        s = slice(i,min(n_train_data,i+batch_size))\n",
    "        xb,yb = x_train[s], y_train[s]\n",
    "        preds = model(xb)\n",
    "        loss = F.cross_entropy(preds,yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "    acc = accuracy(preds,yb)\n",
    "    print(f\"current epoch= {epoch}, current loss = {loss:.2f}, accuracy = {acc:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad0d65f-afe4-4f6d-a684-281f41577735",
   "metadata": {},
   "source": [
    "### Reimplementing Datasets and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27aeed40-aa7b-4b0d-87d3-70f620587e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self,train_data,label_data):\n",
    "        self.train_data = train_data\n",
    "        self.label_data = label_data\n",
    "    def __len__(self):\n",
    "        return len(self.train_data)\n",
    "    def __getitem__(self,i):\n",
    "        return self.train_data[i],self.label_data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c91f8e13-7c06-4a23-91cb-6d78d08c6da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset(x_train,y_train)\n",
    "val_ds = Dataset(x_valid,y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f9ae6a28-f218-47a6-95f1-9e455c405a5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([5, 0, 4, 1, 9]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "050e8b0f-0b0d-4d9d-899b-e9410ef5ef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloader:\n",
    "    def __init__(self,dataset,batch_size=50):\n",
    "        self.dataset=dataset\n",
    "        self.batch_size=batch_size\n",
    "        self.n = len(dataset)\n",
    "    \n",
    "    def __iter__(self):\n",
    "        for i in range(0,self.n,self.batch_size):\n",
    "            s = slice(i,min(self.n,i+self.batch_size))\n",
    "            yield self.dataset[s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f030903-3ce4-431b-ac25-c2c1a509e084",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = Dataloader(train_ds)\n",
    "val_dl = Dataloader(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "957f4dae-8fed-4d9d-bbd6-6ca5468cbeb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current epoch= 0 \n",
      "current train loss = 0.12, train accuracy = 0.96\n",
      "current val loss = 0.13, train accuracy = 0.96 \n",
      "\n",
      "current epoch= 1 \n",
      "current train loss = 0.09, train accuracy = 0.97\n",
      "current val loss = 0.13, train accuracy = 0.97 \n",
      "\n",
      "current epoch= 2 \n",
      "current train loss = 0.07, train accuracy = 0.98\n",
      "current val loss = 0.14, train accuracy = 0.96 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "### traing using our implemented dataloader\n",
    "for epoch in range(epochs):\n",
    "    count = 0\n",
    "    train_loss = 0\n",
    "    train_accuracy = 0\n",
    "    for xb,yb in train_dl:\n",
    "        preds = model(xb)\n",
    "        loss = F.cross_entropy(preds,yb)\n",
    "        train_loss += loss\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        opt.zero_grad()\n",
    "        train_accuracy += accuracy(preds,yb)\n",
    "        count+=1\n",
    "    \n",
    "    train_loss/=count\n",
    "    train_accuracy/=count\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    count = 0\n",
    "    val_accuracy = 0\n",
    "    \n",
    "    for xb,yb in val_dl:\n",
    "        val_preds = model(xb)\n",
    "        val_loss+= F.cross_entropy(val_preds,yb)\n",
    "        val_accuracy += accuracy(val_preds,yb)\n",
    "        count+=1\n",
    "    \n",
    "    val_loss/=count\n",
    "    val_accuracy/=count\n",
    "    \n",
    "    print(f\"current epoch= {epoch} \")\n",
    "    print(f\"current train loss = {train_loss:.2f}, train accuracy = {train_accuracy:.2f}\")\n",
    "    print(f\"current val loss = {val_loss:.2f}, train accuracy = {val_accuracy:.2f} \\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffa8834-9a12-477b-9f1a-83e4439d6907",
   "metadata": {},
   "source": [
    "### Random sampling Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1e545625-07f4-42ba-a75d-a2b04be1094c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4cf39b30-0275-4a49-bf7a-aa3ec2900c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler:\n",
    "    def __init__(self,dataset,shuffle=False):\n",
    "        self.n = len(dataset)\n",
    "        self.shuffle = shuffle\n",
    "    def __iter__(self):\n",
    "        result = list(range(self.n))\n",
    "        if self.shuffle:\n",
    "            random.shuffle(result)\n",
    "        return iter(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "196bc304-2789-4998-95a6-1ead79d535c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = Sampler(train_ds,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "78ba949b-5769-46d8-8434-2591199d2cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8696363-ac1e-4e15-8b90-8a636df83837",
   "metadata": {},
   "outputs": [],
   "source": [
    "zip()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
